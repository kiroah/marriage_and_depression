{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7061f7b1-fbd0-4fcf-a6e1-3f76d3da6fba",
   "metadata": {},
   "source": [
    "## General assumptions about the data\n",
    "   * SUTVA - We assume there's no spillover effect, and marriage \"treatment\" is the same across people. The latter is fixed such that marriage = having legal notice, but the effect is hard to justify it is equal among everyone. Nevertheless, we will assume so. \n",
    "   * Randomness - The survey users are randomly chosen. Even if we assume the survey users are chosen randomly (to represent the US population), the dropout may not be random, which may have some bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d7bc3-55cc-4e8c-9b1a-a1055fe455bc",
   "metadata": {},
   "source": [
    "## Notes\n",
    "   * This is using logitudinal data however it's not really a panel data analysis since we are not comparing two points in time (as data is not available)\n",
    "   * We will mainly use the 2019 data as it's pre-COVID, but may look at 2021 data for comparison\n",
    "   * To reduce dependency between rounds (i.e. need to run previous rounds prior to running next round), some code may be redundant between rounds\n",
    "   * At some point PCA can be used but is not being done here as I have not really studied PCA yet. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90ad8f-88c4-41c2-8acb-6378a660ec46",
   "metadata": {},
   "source": [
    "## Rough course of action\n",
    "\n",
    "1. Decide on datapoints \n",
    "2. Prepare "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a7d459-36ef-435a-8b56-ff3704e4365e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64961d6-d54e-4f84-889c-e74b2e168542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import re\n",
    "from itables import init_notebook_mode\n",
    "from itables import show\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5305c-7ba2-475d-842d-a809bbe6982f",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3af025-79d4-49e0-aa85-3f8ac42ae1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_year = 2019\n",
    "target_outcome = 'CESD_above_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d30868-8f3d-435c-ba3d-67fa588424b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def better_colnames(df, from_col: str, to_cols: list[str]  = ['Description','Year']):\n",
    "    ''' Helper function to rename the columns in the (NLS data) df into something readable/helpful, based on data in codebook_df\n",
    "    '''\n",
    "    #Create dataframe with Ref column and the desired new column names based on input\n",
    "    col_mapping = pd.concat([codebook_df[from_col],codebook_df[to_cols[0]].str.cat(codebook_df[to_cols[1:]],sep='_')],axis=1)    \n",
    "    col_mapping.columns.values[1] = '_'.join(to_cols)\n",
    "    #Convert the mapping dataframe to dictionary and rename columns\n",
    "    return(df.rename(columns = col_mapping.set_index(from_col).squeeze().to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc90439-8e49-4430-8ca3-a8a37be05338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tidy_df= pd.read_pickle('tidy_df.pkl')\n",
    "main_df= pd.read_pickle('main_df.pkl')\n",
    "codebook_df= pd.read_pickle('codebook_df.pkl')\n",
    "mental_health_df= pd.read_pickle('mental_health_df.pkl')\n",
    "codebook_df= pd.read_pickle('codebook_df.pkl')\n",
    "cohab_mhealth_df = pd.read_pickle('cohab_mhealth_df.pkl')\n",
    "source_df = pd.read_pickle('source_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e64e71-78d8-4bcb-b740-31c30ca4661b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model data creation\n",
    "\n",
    "tidy_df_cols = {\n",
    "    'uid': 'uid',\n",
    "    'sex': 'sex',\n",
    "    'age_1996': 'age_1996',\n",
    "    'hispanic': 'hispanic',\n",
    "    'race': 'race',\n",
    "    'CV_URBAN_RURAL': 'urban'\n",
    "}\n",
    "source_df_cols = {\n",
    "\n",
    "}\n",
    "    \n",
    "\n",
    "#Initially add columns from tidy_df \n",
    "model_data_df = tidy_df.loc[tidy_df['Year'] == target_year,list(tidy_df_cols.keys()),]\n",
    "\n",
    "#Add source_df columns\n",
    "#model_data_df = model_data_df.merge(source_df.loc[:,['uid'] + list(source_df_cols.keys())],on='uid')\n",
    "\n",
    "\n",
    "#Add derived columns from previous work\n",
    "cohab_mhealth_cols = ['uid','Rxx_CESD_SCORE_(x_ITEM)','married',target_outcome]\n",
    "model_data_df = model_data_df.merge(cohab_mhealth_df.loc[cohab_mhealth_df['Year']==2019,cohab_mhealth_cols],on='uid')\n",
    "model_data_df = model_data_df.rename(columns={'Rxx_CESD_SCORE_(x_ITEM)':'CESD'})\n",
    "\n",
    "#converting the main treatment to int\n",
    "#Since there are three states (Married, Not married but married before, Never married), we will create two separate columns \n",
    "model_data_df['married_vs_not_married'] = (model_data_df['married'] == 'Yes').astype(int)\n",
    "model_data_df['married_vs_never_married'] = (model_data_df['married'] == 'Yes').astype(int)\n",
    "#For married VS never married, the \"Married but married before\" users will be marked as NaN\n",
    "model_data_df.loc[model_data_df['married']=='No',['married_vs_never_married']] = np.nan\n",
    "\n",
    "model_data_df.rename(columns=tidy_df_cols,inplace=True)\n",
    "#model_data_df.rename(columns=source_df_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b9e4ce-cad1-4634-b02a-b3b42aafdba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Currently a lot of the columns are stored as sparse data. Some models choke as they don't handle such datatype. \n",
    "# Therefore, changing them to dense\n",
    "\n",
    "def dense_columns(col):\n",
    "    if (isinstance(col.dtype, pd.SparseDtype)): \n",
    "        return col.sparse.to_dense()\n",
    "    else:\n",
    "        return col\n",
    "    \n",
    "model_data_df = model_data_df.apply(dense_columns,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44baa2e3-8d5f-4e36-a4ae-8b97034ad1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create BMI columns. Since height and weight not mentioned every year, need to pull from last known\n",
    "\n",
    "#Get index for last known weight and height \n",
    "last_known_wgt_idx = tidy_df.loc[(tidy_df['YSAQ_000B'].notnull()) & (tidy_df['YSAQ_000B'] > 0),:].groupby('uid')['YSAQ_000B'].idxmax()\n",
    "last_known_hgt_idx = tidy_df.loc[(tidy_df['YSAQ_000A000001'].notnull()) & (tidy_df['YSAQ_000A000001'] > 0)\n",
    "                                 & (tidy_df['YSAQ_000A000002'].notnull()) & (tidy_df['YSAQ_000A000002'] >= 0)\n",
    "                                 ,:].groupby('uid')['YSAQ_000A000001'].idxmax()\n",
    "\n",
    "\n",
    "#Using the values above, get bmi\n",
    "bmi_df = tidy_df.loc[last_known_wgt_idx,['uid','YSAQ_000B']]\n",
    "bmi_df = bmi_df.merge(tidy_df.loc[last_known_hgt_idx,['uid','YSAQ_000A000001','YSAQ_000A000002']],on='uid',how='left')\n",
    "bmi_df['bmi'] = bmi_df['YSAQ_000B'] / ((bmi_df['YSAQ_000A000001'] * 12 + bmi_df['YSAQ_000A000002']) ** 2) * 703\n",
    "\n",
    "model_data_df.drop(['bmi','bmi_bin'],inplace=True,errors='ignore')\n",
    "model_data_df = model_data_df.merge(bmi_df[['uid','bmi']], on='uid',how='left')\n",
    "\n",
    "#Imputing bmi based on US average. Technically the average is different per male and female, but it's slight difference\n",
    "# (29.1 VS 29.6) so just using the same value.\n",
    "model_data_df['bmi'] = model_data_df['bmi'].fillna(29.4)\n",
    "\n",
    "#Create bin\n",
    "model_data_df['bmi_bin'] = ''\n",
    "model_data_df.loc[model_data_df['bmi'] < 18.5,'bmi_bin'] = 'under'\n",
    "model_data_df.loc[model_data_df['bmi'].between(18.5, 25.0,inclusive='left'),'bmi_bin'] = 'normal'\n",
    "model_data_df.loc[model_data_df['bmi'].between(25.0, 29.0,inclusive='left'),'bmi_bin'] = 'over'\n",
    "model_data_df.loc[model_data_df['bmi'] > 29.0,'bmi_bin'] = 'obese'\n",
    "model_data_df['bmi_bin'] = model_data_df['bmi_bin'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67a9079d-35ec-4523-9807-b3840692d45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Flipping urban variable values (0:rural 1:urban 2:unknown) to somewhat more ordinal (0:unknown 1:rural 2:urban)\n",
    "\n",
    "model_data_df['urban'] = model_data_df['urban'].map({0:1,1:2,2:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3563b4d5-9cef-4adb-8f7d-e19647be54cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use the '.sparse' accessor with Sparse data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_data_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py:31\u001b[0m, in \u001b[0;36mBaseAccessor.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py:237\u001b[0m, in \u001b[0;36mSparseFrameAccessor._validate\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    235\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(t, SparseDtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m dtypes):\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validation_msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use the '.sparse' accessor with Sparse data."
     ]
    }
   ],
   "source": [
    "model_data_df.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6e67a59-5e8f-4352-b5ba-708e75f1af3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform std with type Sparse[float64, nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_data_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:10940\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[1;34m(self, percentiles, include, exclude, datetime_is_numeric)\u001b[0m\n\u001b[0;32m  10691\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  10692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(\n\u001b[0;32m  10693\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDFrameT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10697\u001b[0m     datetime_is_numeric: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m  10698\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m  10699\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  10700\u001b[0m \u001b[38;5;124;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[0;32m  10701\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10938\u001b[0m \u001b[38;5;124;03m    max            NaN      3.0\u001b[39;00m\n\u001b[0;32m  10939\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 10940\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdescribe_ndframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10942\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatetime_is_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_is_numeric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\describe.py:101\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[1;34m(obj, include, exclude, datetime_is_numeric, percentiles)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     describer \u001b[38;5;241m=\u001b[39m DataFrameDescriber(\n\u001b[0;32m     95\u001b[0m         obj\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj),\n\u001b[0;32m     96\u001b[0m         include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[0;32m     97\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     98\u001b[0m         datetime_is_numeric\u001b[38;5;241m=\u001b[39mdatetime_is_numeric,\n\u001b[0;32m     99\u001b[0m     )\n\u001b[1;32m--> 101\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdescriber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\describe.py:181\u001b[0m, in \u001b[0;36mDataFrameDescriber.describe\u001b[1;34m(self, percentiles)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, series \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    180\u001b[0m     describe_func \u001b[38;5;241m=\u001b[39m select_describe_func(series, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatetime_is_numeric)\n\u001b[1;32m--> 181\u001b[0m     ldesc\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdescribe_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    183\u001b[0m col_names \u001b[38;5;241m=\u001b[39m reorder_columns(ldesc)\n\u001b[0;32m    184\u001b[0m d \u001b[38;5;241m=\u001b[39m concat(\n\u001b[0;32m    185\u001b[0m     [x\u001b[38;5;241m.\u001b[39mreindex(col_names, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ldesc],\n\u001b[0;32m    186\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    187\u001b[0m     sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\describe.py:242\u001b[0m, in \u001b[0;36mdescribe_numeric_1d\u001b[1;34m(series, percentiles)\u001b[0m\n\u001b[0;32m    238\u001b[0m formatted_percentiles \u001b[38;5;241m=\u001b[39m format_percentiles(percentiles)\n\u001b[0;32m    240\u001b[0m stat_index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m formatted_percentiles \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    241\u001b[0m d \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 242\u001b[0m     [series\u001b[38;5;241m.\u001b[39mcount(), series\u001b[38;5;241m.\u001b[39mmean(), \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, series\u001b[38;5;241m.\u001b[39mmin()]\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;241m+\u001b[39m series\u001b[38;5;241m.\u001b[39mquantile(percentiles)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;241m+\u001b[39m [series\u001b[38;5;241m.\u001b[39mmax()]\n\u001b[0;32m    245\u001b[0m )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# GH#48340 - always return float on non-complex numeric data\u001b[39;00m\n\u001b[0;32m    247\u001b[0m dtype: DtypeObj \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:11717\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.std\u001b[1;34m(self, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11697\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11698\u001b[0m     _num_ddof_doc,\n\u001b[0;32m  11699\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn sample standard deviation over requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11715\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11716\u001b[0m ):\n\u001b[1;32m> 11717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:11305\u001b[0m, in \u001b[0;36mNDFrame.std\u001b[1;34m(self, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstd\u001b[39m(\n\u001b[0;32m  11297\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11298\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11303\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11304\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function_ddof\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11306\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  11307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:11266\u001b[0m, in \u001b[0;36mNDFrame._stat_function_ddof\u001b[1;34m(self, name, func, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11256\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  11257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  11258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11261\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  11262\u001b[0m     )\n\u001b[0;32m  11263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  11264\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, ddof\u001b[38;5;241m=\u001b[39mddof\n\u001b[0;32m  11265\u001b[0m     )\n\u001b[1;32m> 11266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\n\u001b[0;32m  11268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\series.py:4797\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   4795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delegate, ExtensionArray):\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;66;03m# dispatch to ExtensionArray interface\u001b[39;00m\n\u001b[1;32m-> 4797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdelegate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4800\u001b[0m     \u001b[38;5;66;03m# dispatch to numpy arrays\u001b[39;00m\n\u001b[0;32m   4801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_numeric_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\sparse\\array.py:1447\u001b[0m, in \u001b[0;36mSparseArray._reduce\u001b[1;34m(self, name, skipna, **kwargs)\u001b[0m\n\u001b[0;32m   1444\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot perform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skipna:\n\u001b[0;32m   1450\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform std with type Sparse[float64, nan]"
     ]
    }
   ],
   "source": [
    "model_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c985c-21ae-4e1f-a279-3a613de2aabb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Round 0 - Logistic regression w/ only treatment variable\n",
    "   * Use logistic regression w/ married_vs_never_married only\n",
    "   * Odds increase = 2.3x, w/ p-value < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "309c7a74-58c4-458a-9e48-5d30cc3f1737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_model_data_df = model_data_df.copy()\n",
    "temp_model_data_df.dropna(axis=0,subset='married_vs_never_married',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "288a9d0f-77e4-4894-9847-e4b5c66e760f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESD_above_8 ~ married_vs_never_married\n",
      "                               Generalized Linear Model Regression Results                               \n",
      "=========================================================================================================\n",
      "Dep. Variable:     ['CESD_above_8[False]', 'CESD_above_8[True]']   No. Observations:                 5835\n",
      "Model:                                                       GLM   Df Residuals:                     5833\n",
      "Model Family:                                           Binomial   Df Model:                            1\n",
      "Link Function:                                             Logit   Scale:                          1.0000\n",
      "Method:                                                     IRLS   Log-Likelihood:                -1700.2\n",
      "Date:                                           Wed, 07 Aug 2024   Deviance:                       3400.5\n",
      "Time:                                                   08:36:06   Pearson chi2:                 5.83e+03\n",
      "No. Iterations:                                                6   Pseudo R-squ. (CS):            0.01333\n",
      "Covariance Type:                                       nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    1.9720      0.058     34.118      0.000       1.859       2.085\n",
      "married_vs_never_married     0.8372      0.097      8.603      0.000       0.646       1.028\n",
      "============================================================================================\n",
      "Log odds increase when married: 2.309805355668216 \n",
      "P-value: 7.766372103632972e-18 \n"
     ]
    }
   ],
   "source": [
    "formula = target_outcome +  ' ~ married_vs_never_married'\n",
    "print(formula)\n",
    "# Fit the logistic regression model using GLM\n",
    "model = smf.glm(formula=formula, data=temp_model_data_df, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "print(f'Log odds increase when married: {math.exp(model.params[\"married_vs_never_married\"])} ')\n",
    "print(f'P-value: {model.pvalues[\"married_vs_never_married\"]} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c914e7f-5da1-46d8-b8f8-9cbdb4781dff",
   "metadata": {},
   "source": [
    "## Round 1 - Logistic regression w/ few demographics\n",
    "   * Use logistic regression w/ age, race-related & sex as additional explanatory variables\n",
    "   * Additional assumptions\n",
    "      * No unconfounding variables (HAHAHA...) \n",
    "      * Linearity of logit - We should check this but not checking for this round as the above assumption doesn't really hold anyways\n",
    "   * __Result__\n",
    "      * Odds increase: 2.5x\n",
    "      * p-value: < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f698fff4-6f59-4a78-84d7-bfb6ed5e2fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_model_data_df = model_data_df.copy()\n",
    "temp_model_data_df.dropna(axis=0,subset='married_vs_never_married',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "332dbea6-e584-4dcd-a211-f1cdfddab44a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESD_above_8 ~ married_vs_never_married + age_1996 + C(hispanic) + C(sex) + C(race)\n"
     ]
    }
   ],
   "source": [
    "#formula creation\n",
    "\n",
    "Xs_numerical = ['age_1996']\n",
    "Xs_categorical = ['hispanic','sex','race']\n",
    "\n",
    "formula = target_outcome +  ' ~ married_vs_never_married + ' +  (' + '.join(Xs_numerical)) + ' + C(' + (') + C(').join(Xs_categorical) + ')'\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d8de7bd-7ed0-4b06-9903-153069915c69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Generalized Linear Model Regression Results                               \n",
      "=========================================================================================================\n",
      "Dep. Variable:     ['CESD_above_8[False]', 'CESD_above_8[True]']   No. Observations:                 5835\n",
      "Model:                                                       GLM   Df Residuals:                     5822\n",
      "Model Family:                                           Binomial   Df Model:                           12\n",
      "Link Function:                                             Logit   Scale:                          1.0000\n",
      "Method:                                                     IRLS   Log-Likelihood:                -1676.9\n",
      "Date:                                           Wed, 07 Aug 2024   Deviance:                       3353.8\n",
      "Time:                                                   08:36:07   Pearson chi2:                 5.80e+03\n",
      "No. Iterations:                                               20   Pseudo R-squ. (CS):            0.02119\n",
      "Covariance Type:                                       nonrobust                                         \n",
      "========================================================================================================\n",
      "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Intercept                                1.6577      1.223      1.356      0.175      -0.739       4.054\n",
      "C(hispanic)[T.-1]                      -18.4334   1.28e+04     -0.001      0.999   -2.52e+04    2.51e+04\n",
      "C(hispanic)[T.0]                         1.1488      0.878      1.309      0.191      -0.571       2.869\n",
      "C(hispanic)[T.1]                         1.5264      0.882      1.732      0.083      -0.201       3.254\n",
      "C(sex)[T.Male]                           0.5482      0.096      5.726      0.000       0.361       0.736\n",
      "C(race)[T.Asian or Pacific Islander]    -0.3472      0.845     -0.411      0.681      -2.004       1.310\n",
      "C(race)[T.Black or African American]    -0.6424      0.736     -0.873      0.383      -2.084       0.800\n",
      "C(race)[T.Don't know]                   18.0667   1.28e+04      0.001      0.999   -2.51e+04    2.52e+04\n",
      "C(race)[T.Refusal]                      -0.3869      1.089     -0.355      0.722      -2.520       1.747\n",
      "C(race)[T.Something else]               -1.0392      0.751     -1.384      0.166      -2.511       0.433\n",
      "C(race)[T.White]                        -0.8417      0.734     -1.147      0.251      -2.280       0.597\n",
      "married_vs_never_married                 0.9282      0.103      8.972      0.000       0.725       1.131\n",
      "age_1996                                -0.0289      0.034     -0.859      0.390      -0.095       0.037\n",
      "========================================================================================================\n",
      "Log odds increase when married: 2.52991631399275 \n",
      "P-value: 2.9168261023922817e-19 \n"
     ]
    }
   ],
   "source": [
    "# Fit the logistic regression model using GLM\n",
    "model = smf.glm(formula=formula, data=temp_model_data_df, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "print(f'Log odds increase when married: {math.exp(model.params[\"married_vs_never_married\"])} ')\n",
    "print(f'P-value: {model.pvalues[\"married_vs_never_married\"]} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607accd8-0b7d-4ef0-bb2e-631665b4d2dd",
   "metadata": {},
   "source": [
    "## Round 2 - Logistic regression w/ more fields\n",
    "   * Use logistic regression w/ added fields:\n",
    "      * BMI in bins (underweight, normal, over, obese)\n",
    "      * Living in urban or rural place\n",
    "      * Household income at survey year\n",
    "      * Highest degree CVC_HIGHEST_DEGREE_EVER\n",
    "      * Kids\n",
    "      * Number of people in household\n",
    "   * Additional assumptions\n",
    "      * No unconfounding variables (HAHAHA...) \n",
    "      * Linearity of logit - We should check this but not checking for this round as the above assumption doesn't really hold anyways\n",
    "   * __Result__\n",
    "      * Odds increase: 2.5x\n",
    "      * p-value: < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11c020ba-eeb3-4296-822e-c720eacdf9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_model_data_df = model_data_df.copy()\n",
    "temp_model_data_df.dropna(axis=0,subset='married_vs_never_married',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7d63565-c11c-4cce-a08c-7ed5e4559134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CESD_above_8 ~ married_vs_never_married + age_1996 + C(hispanic) + C(sex) + C(race) + C(bmi_bin) + C(urban)\n"
     ]
    }
   ],
   "source": [
    "#formula creation\n",
    "\n",
    "Xs_numerical = ['age_1996',]\n",
    "Xs_categorical = ['hispanic','sex','race','bmi_bin','urban']\n",
    "\n",
    "formula = target_outcome +  ' ~ married_vs_never_married + ' +  (' + '.join(Xs_numerical)) + ' + C(' + (') + C(').join(Xs_categorical) + ')'\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d333b503-8442-43fd-94dc-fc2b69b66a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Generalized Linear Model Regression Results                               \n",
      "=========================================================================================================\n",
      "Dep. Variable:     ['CESD_above_8[False]', 'CESD_above_8[True]']   No. Observations:                 5835\n",
      "Model:                                                       GLM   Df Residuals:                     5815\n",
      "Model Family:                                           Binomial   Df Model:                           19\n",
      "Link Function:                                             Logit   Scale:                          1.0000\n",
      "Method:                                                     IRLS   Log-Likelihood:                -1671.9\n",
      "Date:                                           Wed, 07 Aug 2024   Deviance:                       3343.9\n",
      "Time:                                                   08:47:41   Pearson chi2:                 5.78e+03\n",
      "No. Iterations:                                               20   Pseudo R-squ. (CS):            0.02285\n",
      "Covariance Type:                                       nonrobust                                         \n",
      "========================================================================================================\n",
      "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Intercept                                2.7532      1.428      1.929      0.054      -0.045       5.551\n",
      "C(hispanic)[T.-1]                      -18.0440   1.25e+04     -0.001      0.999   -2.45e+04    2.44e+04\n",
      "C(hispanic)[T.0]                         1.1272      0.885      1.274      0.203      -0.607       2.862\n",
      "C(hispanic)[T.1]                         1.5358      0.888      1.729      0.084      -0.206       3.277\n",
      "C(sex)[T.Male]                           0.5476      0.096      5.681      0.000       0.359       0.737\n",
      "C(race)[T.Asian or Pacific Islander]    -0.4207      0.847     -0.496      0.620      -2.081       1.240\n",
      "C(race)[T.Black or African American]    -0.6188      0.737     -0.839      0.401      -2.063       0.826\n",
      "C(race)[T.Don't know]                   17.7267   1.25e+04      0.001      0.999   -2.44e+04    2.45e+04\n",
      "C(race)[T.Refusal]                      -0.3825      1.093     -0.350      0.726      -2.525       1.760\n",
      "C(race)[T.Something else]               -1.0595      0.752     -1.409      0.159      -2.533       0.414\n",
      "C(race)[T.White]                        -0.8639      0.735     -1.175      0.240      -2.305       0.577\n",
      "C(bmi_bin)[T.obese]                     -0.2357      0.125     -1.888      0.059      -0.480       0.009\n",
      "C(bmi_bin)[T.over]                      -0.0810      0.145     -0.559      0.576      -0.365       0.203\n",
      "C(bmi_bin)[T.under]                      0.7170      0.735      0.975      0.330      -0.724       2.158\n",
      "C(urban)[T.-3]                          -1.7051      1.323     -1.288      0.198      -4.299       0.889\n",
      "C(urban)[T.0]                           -0.9304      0.734     -1.267      0.205      -2.369       0.509\n",
      "C(urban)[T.1]                           -1.0192      0.726     -1.404      0.160      -2.442       0.404\n",
      "C(urban)[T.2]                           -0.8741      0.864     -1.012      0.312      -2.567       0.819\n",
      "married_vs_never_married                 0.9246      0.104      8.895      0.000       0.721       1.128\n",
      "age_1996                                -0.0238      0.034     -0.704      0.481      -0.090       0.042\n",
      "========================================================================================================\n",
      "Log odds increase when married: 2.520946926208212 \n",
      "P-value: 5.834980933453981e-19 \n"
     ]
    }
   ],
   "source": [
    "# Fit the logistic regression model using GLM\n",
    "model = smf.glm(formula=formula, data=temp_model_data_df, family=sm.families.Binomial()).fit()\n",
    "#model = smf.glm(formula=formula, data=temp_model_data_df, family=sm.families.Binomial()).fit_regularized)\n",
    "\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "print(f'Log odds increase when married: {math.exp(model.params[\"married_vs_never_married\"])} ')\n",
    "print(f'P-value: {model.pvalues[\"married_vs_never_married\"]} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef665bc0-1f78-462b-b1d5-573af51b97f7",
   "metadata": {},
   "source": [
    "## RAndom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a470b9-be66-45cc-990b-32d3d3bd49b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show(tidy_df[['CV_URBAN_RURAL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23c44f-2748-4893-b699-ff13e4b17520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hot encode columns & keep the column names on the side for modeling\n",
    "\n",
    "hot_encode_binary = ['sex']\n",
    "hot_encode_others = ['race']\n",
    "\n",
    "# For binary, we'll keep only one column. For others, we won't drop the first column\n",
    "temp_encoded_binaries_df = pd.get_dummies(model_data_df[hot_encode_binary], columns=hot_encode_binary,drop_first=True)\n",
    "temp_encoded_nonbinaries_df = pd.get_dummies(model_data_df[hot_encode_others], columns=hot_encode_others)\n",
    "\n",
    "\n",
    "hot_encoded_columns = temp_encoded_binaries_df.columns.to_list() + temp_encoded_nonbinaries_df.columns.to_list()\n",
    "\n",
    "temp_model_data_df = model_data_df.drop(hot_encode_binary + hot_encode_others, axis=1)\n",
    "temp_model_data_df = pd.concat([temp_model_data_df,temp_encoded_binaries_df, temp_encoded_nonbinaries_df],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
